var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Samplers","page":"API","title":"Samplers","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS introduces a few samplers extending AbstractMCMC. The sample method expects a custom type that subtypes AbstractMCMC.AbstractModel. The available samplers are listed below:","category":"page"},{"location":"api/#SMC","page":"API","title":"SMC","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.SMC","category":"page"},{"location":"api/#AdvancedPS.SMC","page":"API","title":"AdvancedPS.SMC","text":"SMC(n[, resampler = ResampleWithESSThreshold()])\nSMC(n, [resampler = resample_systematic, ]threshold)\n\nCreate a sequential Monte Carlo (SMC) sampler with n particles.\n\nIf the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"The SMC sampler populates a set of particles in a AdvancedPS.ParticleContainer and performs a AdvancedPS.sweep! which  propagates the particles and provides an estimation of the log-evidence","category":"page"},{"location":"api/","page":"API","title":"API","text":"sampler = SMC(nparticles) \nchains = sample(model, sampler)","category":"page"},{"location":"api/#Particle-Gibbs","page":"API","title":"Particle Gibbs","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.PG","category":"page"},{"location":"api/#AdvancedPS.PG","page":"API","title":"AdvancedPS.PG","text":"PG(n, [resampler = ResampleWithESSThreshold()])\nPG(n, [resampler = resample_systematic, ]threshold)\n\nCreate a Particle Gibbs sampler with n particles.\n\nIf the algorithm for the resampling step is not specified explicitly, systematic resampling is performed if the estimated effective sample size per particle drops below 0.5.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"The Particle Gibbs introduced in [2] runs a sequence of conditional SMC steps where a pre-selected particle, the reference particle, is replayed and propagated through  the SMC step.","category":"page"},{"location":"api/","page":"API","title":"API","text":"sampler = PG(nparticles)\nchains = sample(model, sampler, nchains)","category":"page"},{"location":"api/","page":"API","title":"API","text":"For more detailed examples please refer to the Examples page.","category":"page"},{"location":"api/#Resampling","page":"API","title":"Resampling","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS implements adaptive resampling for both AdvancedPS.PG and AdvancedPS.SMC. The following resampling schemes are implemented:","category":"page"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.resample_multinomial\nAdvancedPS.resample_residual\nAdvancedPS.resample_stratified\nAdvancedPS.resample_systematic","category":"page"},{"location":"api/#AdvancedPS.resample_multinomial","page":"API","title":"AdvancedPS.resample_multinomial","text":"resample_multinomial(rng, weights, n)\n\nReturn a vector of n samples x₁, ..., xₙ from the numbers 1, ..., length(weights), generated by multinomial resampling.\n\nThe new indices are sampled from the multinomial distribution with probabilities equal to weights\n\n\n\n\n\n","category":"function"},{"location":"api/#AdvancedPS.resample_residual","page":"API","title":"AdvancedPS.resample_residual","text":"resample_residual(rng, weights, n)\n\nReturn a vector of n samples x₁, ..., xₙ from the numbers 1, ..., length(weights), generated by residual resampling.\n\nIn residual resampling we start by duplicating all the particles whose weight is bigger than 1/n. We copy each of these particles N_i times where\n\nN_i = leftlfloor n w_i rightrfloor\n\nWe then duplicate the R_t = n - sum_i N_i missing particles using multinomial resampling with the residual weights given by:\n\ntildew = w_i - fracN_iN\n\n\n\n\n\n","category":"function"},{"location":"api/#AdvancedPS.resample_stratified","page":"API","title":"AdvancedPS.resample_stratified","text":"resample_stratified(rng, weights, n)\n\nReturn a vector of n samples x₁, ..., xₙ from the numbers 1, ..., length(weights), generated by stratified resampling.\n\nIn stratified resampling n ordered random numbers u₁, ..., uₙ are generated, where\n\nuₖ sim U(k - 1)  n k  n). \n\nBased on these numbers the samples x₁, ..., xₙ are selected according to  the multinomial distribution defined by the normalized weights, i.e., xᵢ = j if and only if\n\nuᵢ in leftsum_s=1^j-1 weights_s sum_s=1^j weights_sright).\n\n\n\n\n\n","category":"function"},{"location":"api/#AdvancedPS.resample_systematic","page":"API","title":"AdvancedPS.resample_systematic","text":"resample_systematic(rng, weights, n)\n\nReturn a vector of n samples x₁, ..., xₙ from the numbers 1, ..., length(weights), generated by systematic resampling.\n\nIn systematic resampling a random number u sim U0 1) is used to generate n ordered numbers u₁, ..., uₙ where \n\nuₖ = (u + k  1)  n. \n\nBased on these numbers the samples x₁, ..., xₙ are selected according to  the multinomial distribution defined by the normalized weights, i.e., xᵢ = j if and only if\n\nuᵢ in leftsum_s=1^j-1 weights_s sum_s=1^j weights_sright)\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"Each of these schemes is wrapped in a AdvancedPS.ResampleWithESSThreshold struct to trigger a resampling step whenever the ESS is below a certain threshold.","category":"page"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.ResampleWithESSThreshold","category":"page"},{"location":"api/#AdvancedPS.ResampleWithESSThreshold","page":"API","title":"AdvancedPS.ResampleWithESSThreshold","text":"ResampleWithESSThreshold{R,T<:Real}\n\nPerform resampling using R if the effective sample size is below T. By default we use resample_systematic with a threshold of 0.5\n\n\n\n\n\n","category":"type"},{"location":"api/#RNG","page":"API","title":"RNG","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS replays the individual trajectories instead of storing the intermediate values. This way we can build efficient samplers.  However in order to replay the trajectories we need to reproduce most of the random numbers generated  during the execution of the program while also generating diverging traces after each resampling step.  To solve these two issues AdvancedPS uses counter-based RNG introduced in [1] and widely used in large parallel systems see  StochasticDifferentialEquations or JAX for other implementations. ","category":"page"},{"location":"api/","page":"API","title":"API","text":"Under the hood AdvancedPS is using Random123 for the generators. Using counter-based RNG allows us to split generators thus creating new independent random streams. These generators are also wrapped in a AdvancedPS.TracedRNG type.  The TracedRNG keeps track of the keys generated at every split and can be reset to replay random streams.","category":"page"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.TracedRNG\nAdvancedPS.split\nAdvancedPS.load_state!\nAdvancedPS.save_state!","category":"page"},{"location":"api/#AdvancedPS.TracedRNG","page":"API","title":"AdvancedPS.TracedRNG","text":"TracedRNG{R,N,T}\n\nWrapped random number generator from Random123 to keep track of random streams during model evaluation\n\n\n\n\n\n","category":"type"},{"location":"api/#AdvancedPS.split","page":"API","title":"AdvancedPS.split","text":"split(key::Integer, n::Integer=1)\n\nSplit key into n new keys\n\n\n\n\n\n","category":"function"},{"location":"api/#AdvancedPS.load_state!","page":"API","title":"AdvancedPS.load_state!","text":"load_state!(r::TracedRNG)\n\nLoad state from current model iteration. Random streams are now replayed\n\n\n\n\n\n","category":"function"},{"location":"api/#AdvancedPS.save_state!","page":"API","title":"AdvancedPS.save_state!","text":"save_state!(r::TracedRNG)\n\nAdd current key of the inner rng in r to keys.\n\n\n\n\n\n","category":"function"},{"location":"api/#Internals","page":"API","title":"Internals","text":"","category":"section"},{"location":"api/#Particle-Sweep","page":"API","title":"Particle Sweep","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AdvancedPS.ParticleContainer\nAdvancedPS.sweep!","category":"page"},{"location":"api/#AdvancedPS.ParticleContainer","page":"API","title":"AdvancedPS.ParticleContainer","text":"Data structure for particle filters\n\neffectiveSampleSize(pc :: ParticleContainer): Return the effective sample size of the particles in pc\n\n\n\n\n\n","category":"type"},{"location":"api/#AdvancedPS.sweep!","page":"API","title":"AdvancedPS.sweep!","text":"sweep!(rng, pc::ParticleContainer, resampler)\n\nPerform a particle sweep and return an unbiased estimate of the log evidence.\n\nThe resampling steps use the given resampler.\n\nReference\n\nDel Moral, P., Doucet, A., & Jasra, A. (2006). Sequential monte carlo samplers. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(3), 411-436.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"[1]: John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw. 2011. Parallel random numbers: as easy as 1, 2, 3. In Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC '11). Association for Computing Machinery, New York, NY, USA, Article 16, 1–12. DOI:https://doi.org/10.1145/2063384.2063405","category":"page"},{"location":"api/","page":"API","title":"API","text":"[2]: Andrieu, Christophe, Arnaud Doucet, and Roman Holenstein. \"Particle Markov chain Monte Carlo methods.\" Journal of the Royal Statistical Society: Series B (Statistical Methodology) 72, no. 3 (2010): 269-342.","category":"page"},{"location":"examples/gaussian-ssm/#Particle-Gibbs-with-Ancestor-Sampling","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"","category":"section"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"using AdvancedPS\nusing Random\nusing Distributions\nusing Plots","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"We consider the following linear state-space model with Gaussian innovations. The latent state is a simple gaussian random walk and the observation is linear in the latent states, namely:","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"$","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"x{t+1} = a x{t} + \\epsilont \\quad \\epsilont \\sim \\mathcal{N}(0,q^2) $ $  y{t} = x{t} + \\nu_{t} \\quad \\nu \\sim \\mathcal{N}(0, r^2) $","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"Here we assume the static parameters theta = (a q^2 r^2) are known and we are only interested in sampling from the latent state x_t. To use particle gibbs with the ancestor sampling step we need to provide both the transition and observation densities. From the definition above we get: $  x{t+1} \\sim f{\\theta}(xt|xt) = \\mathcal{N}(a xt, q^2) $ $  yt \\sim g{\\theta}(xt|xt) = \\mathcal{N}(a xt, q^2) $ as well as the initial distribution f_0(x) = mathcalN(0 q^2(1-a^2)).","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"We are ready to use AdvancedPS with our model. We first need to define a model type that subtypes AdvancedPS.AbstractStateSpaceModel.","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"Parameters = @NamedTuple begin\n    a::Float64\n    q::Float64\n    r::Float64\nend\n\nmutable struct NonLinearTimeSeries <: AdvancedPS.AbstractStateSpaceModel\n    X::Vector{Float64}\n    θ::Parameters\n    NonLinearTimeSeries(θ::Parameters) = new(Vector{Float64}(), θ)\nend","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"and the densities defined above.","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"f(m::NonLinearTimeSeries, state, t) = Normal(m.θ.a * state, m.θ.q) # Transition density\ng(m::NonLinearTimeSeries, state, t) = Normal(state, m.θ.r)         # Observation density\nf₀(m::NonLinearTimeSeries) = Normal(0, m.θ.q^2 / (1 - m.θ.a^2))    # Initial state density","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"To implement AdvancedPS.AbstractStateSpaceModel we need to define a few functions to define the dynamics of our system.","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"AdvancedPS.initialization the initial state density\nAdvancedPS.transition the state transition density\nAdvancedPS.observation the observation score given the observed data\nAdvancedPS.isdone signals the end of the execution for the model","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"AdvancedPS.initialization(model::NonLinearTimeSeries) = f₀(model)\nAdvancedPS.transition(model::NonLinearTimeSeries, state, step) = f(model, state, step)\nfunction AdvancedPS.observation(model::NonLinearTimeSeries, state, step)\n    return logpdf(g(model, state, step), y[step])\nend\nAdvancedPS.isdone(::NonLinearTimeSeries, step) = step > Tₘ","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"Everything is now ready to simulate some data.","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"a = 0.9   # Scale\nq = 0.32  # State variance\nr = 1     # Observation variance\nTₘ = 300  # Number of observation\nNₚ = 50   # Number of particles\nNₛ = 1000 # Number of samples\nseed = 9  # Reproduce everything\n\nθ₀ = Parameters((a, q, r))\n\nrng = Random.MersenneTwister(seed)\n\nx = zeros(Tₘ)\ny = zeros(Tₘ)\n\nreference = NonLinearTimeSeries(θ₀)\nx[1] = rand(rng, f₀(reference))\nfor t in 1:Tₘ\n    if t < Tₘ\n        x[t + 1] = rand(rng, f(reference, x[t], t))\n    end\n    y[t] = rand(rng, g(reference, x[t], t))\nend","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"Let's have a look at the simulated data from the latent state dynamics","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"plot(x; label=\"x\", color=:black)\nxlabel!(\"t\")","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"(Image: )","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"and the observation data","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"plot(y; label=\"y\", color=:black)\nxlabel!(\"x\")","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"(Image: )","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"model = NonLinearTimeSeries(θ₀)\npgas = AdvancedPS.PGAS(Nₚ)\nchains = sample(rng, model, pgas, Nₛ, progress=false)","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"The actual sampled trajectory is in the trajectory inner model","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"particles = hcat([chain.trajectory.model.X for chain in chains]...) # Concat all sampled states\nmean_trajectory = mean(particles; dims=2)","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"scatter(particles; label=false, opacity=0.01, color=:black)\nplot!(x; color=:red, label=\"Original Trajectory\")\nplot!(mean_trajectory; color=:orange, label=\"Mean trajectory\", opacity=0.9)\nxlabel!(\"t\")\nylabel!(\"State\")","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"(Image: )","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"By sampling an ancestor from the reference particle in the particle gibbs sampler we","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"update_rate = sum(abs.(diff(particles; dims=2)) .> 0; dims=2) / Nₛ\nplot(update_rate; label=false, ylim=[0, 1], legend=:bottomleft)\nhline!([1 - 1 / Nₚ]; label=\"N: $(Nₚ)\")\nxlabel!(\"Iteration\")\nylabel!(\"Update rate\")","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"(Image: )","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"","category":"page"},{"location":"examples/gaussian-ssm/","page":"Particle Gibbs with Ancestor Sampling","title":"Particle Gibbs with Ancestor Sampling","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#AdvancedPS:-Particle-Samplers-for-Julia","page":"Home","title":"AdvancedPS: Particle Samplers for Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a lightweight package that implements particle based Monte Carlo algorithms for the Turing ecosystem.","category":"page"},{"location":"#Installing-from-Julia","page":"Home","title":"Installing from Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the package, use the following command inside the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"AdvancedPS\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"To load the package, use the command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using AdvancedPS","category":"page"},{"location":"example/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"example/","page":"Examples","title":"Examples","text":"The following pages walk you through some examples using AdvancedPS and the Turing ecosystem.","category":"page"}]
}
